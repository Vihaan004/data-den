#!/usr/bin/env python3
"""
Simple GPU Mentor App Launcher

This script provides a simple way to launch the GPU Mentor application.
"""

import sys
import os
import subprocess

def install_requirements():
    """Install required packages."""
    print("üì¶ Installing required packages...")
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "-r", "requirements.txt"
        ])
        print("‚úÖ Requirements installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error installing requirements: {e}")
        return False

def main():
    """Main launcher function."""
    print("üöÄ GPU Mentor Application Launcher")
    print("=" * 40)
    
    # Check if requirements are installed
    try:
        import gradio
        print("‚úÖ Dependencies already installed")
    except ImportError:
        print("üì¶ Installing dependencies...")
        if not install_requirements():
            sys.exit(1)
    
    # Check if Ollama is available
    try:
        import requests
        import socket
        from config import OLLAMA_PORT
        
        # Try supercomputer-style connection first
        host_node = socket.gethostname()
        try:
            response = requests.get(f"http://vpatel69@{host_node}:{OLLAMA_PORT}/api/tags", timeout=5)
            if response.status_code == 200:
                print("‚úÖ Ollama server is running (supercomputer style)")
            else:
                print("‚ö†Ô∏è Ollama server responded with unexpected status")
        except:
            # Try standard connection
            try:
                response = requests.get(f"http://localhost:{OLLAMA_PORT}/api/tags", timeout=5)
                if response.status_code == 200:
                    print("‚úÖ Ollama server is running (standard)")
                else:
                    print("‚ö†Ô∏è Ollama server responded with unexpected status")
            except:
                print(f"‚ö†Ô∏è Ollama server not detected on port {OLLAMA_PORT} (some features may be limited)")
    except:
        print("‚ö†Ô∏è Could not check Ollama status")
    
    # Launch the app
    print("\nüåê Starting GPU Mentor Application...")
    try:
        # Import and run the app
        from app import GPUMentorApp
        app = GPUMentorApp()
        print("üéâ Application ready! Opening in your browser...")
        app.launch(share=True)
    except KeyboardInterrupt:
        print("\nüëã Application stopped by user")
    except Exception as e:
        print(f"‚ùå Error starting application: {e}")
        print("\nTroubleshooting:")
        print("1. Make sure all requirements are installed: pip install -r requirements.txt")
        print("2. Start Ollama server: ollama serve")
        print("3. Install Ollama model: ollama pull qwen2.5-coder:14b")

if __name__ == "__main__":
    main()
